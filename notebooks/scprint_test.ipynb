{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 24,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "^C\n",
                                    "Traceback (most recent call last):\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/bin/lamin\", line 5, in <module>\n",
                                    "    from lamin_cli.__main__ import main\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/lamin_cli/__main__.py\", line 11, in <module>\n",
                                    "    import rich_click as click\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/__init__.py\", line 73, in <module>\n",
                                    "    from . import rich_click as rich_click\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/rich_click.py\", line 6, in <module>\n",
                                    "    import rich.columns\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/columns.py\", line 7, in <module>\n",
                                    "    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/console.py\", line 57, in <module>\n",
                                    "    from .markup import render as render_markup\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 674, in _load_unlocked\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 541, in _init_module_attrs\n",
                                    "KeyboardInterrupt\n"
                              ]
                        }
                  ],
                  "source": [
                        "! lamin load scprint"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Seed set to 42\n",
                                    "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/bitsandbytes/cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
                                    "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
                                    "ðŸ’¡ connected lamindb: jkobject/scprint\n"
                              ]
                        }
                  ],
                  "source": [
                        "from lightning.pytorch import Trainer, seed_everything\n",
                        "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
                        "\n",
                        "seed_everything(42, workers=True)\n",
                        "\n",
                        "from scprint import scPrint\n",
                        "from scprint.trainer import TrainingMode\n",
                        "from scdataloader import DataModule \n",
                        "import pandas as pd\n",
                        "from scdataloader.utils import load_genes\n",
                        "\n",
                        "import torch\n",
                        "torch.set_float32_matmul_precision('medium')\n",
                        "\n",
                        "%load_ext autoreload\n",
                        "%autoreload 2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# TODO: drop tissue & dev stage until part or is taken in account\n",
                        "\n",
                        "hierarchical_labels = [\n",
                        "    \"cell_type_ontology_term_id\", #1\n",
                        "    # \"tissue_ontology_term_id\",\n",
                        "    \"disease_ontology_term_id\", # 2\n",
                        "#    \"development_stage_ontology_term_id\",\n",
                        "    \"assay_ontology_term_id\", #3\n",
                        "    'self_reported_ethnicity_ontology_term_id', #4\n",
                        "]\n",
                        "labels_to_pred = hierarchical_labels+[\n",
                        "    'sex_ontology_term_id', #5\n",
                        "    \"organism_ontology_term_id\", #6\n",
                        "]\n",
                        "all_labels = labels_to_pred+[\n",
                        "    #'dataset_id',\n",
                        "    'cell_culture',\n",
                        "    \"heat_diff\",\n",
                        "    \"total_counts\",\n",
                        "    \"nnz\",\n",
                        "    \"dpt_group\",\n",
                        "]\n",
                        "\n",
                        "gene_emb = '../data/main/gene_embeddings.parquet'\n",
                        "d_model=128"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": []
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "won't do any check but we recommend to have your dataset coming from local storage\n",
                                    "100.0% are aligned\n",
                                    "total dataset size is 97.032938749 Gb\n",
                                    "---\n",
                                    "dataset contains:\n",
                                    "     4926521 cells\n",
                                    "     127057 genes\n",
                                    "     11 labels\n",
                                    "     6 clss_to_pred\n",
                                    "     4 hierarchical_clss\n",
                                    "     2 organisms\n",
                                    "dataset contains 229 classes to predict\n",
                                    "\n",
                                    "seeing a string: loading gene positions as biomart parquet file\n",
                                    "these files will be considered test datasets:\n",
                                    "    /pasteur/zeus/projets/p02/ml4ig_hot/Users/jkalfon/scprint/.lamindb/BljRloq1xjcxRNDpejzI.h5ad\n",
                                    "    /pasteur/zeus/projets/p02/ml4ig_hot/Users/jkalfon/scprint/.lamindb/yBCKp6HmXuHa0cZptMo7.h5ad\n",
                                    "perc test:  0.0057480725242011555\n"
                              ]
                        }
                  ],
                  "source": [
                        "datamodule = DataModule(\n",
                        "    collection_name=\"preprocessed dataset\",\n",
                        "    gene_embeddings=gene_emb,\n",
                        "    all_labels=all_labels,\n",
                        "    hierarchical_labels=hierarchical_labels,\n",
                        "    organisms=[\"NCBITaxon:9606\", \"NCBITaxon:10090\"],\n",
                        "    how=\"random expr\",\n",
                        "    max_len=1200,\n",
                        "    add_zero_genes=0,\n",
                        "    # how much more you will see the most present vs less present category \n",
                        "    weight_scaler=10,\n",
                        "    label_to_weight=labels_to_pred,\n",
                        "    label_to_pred=labels_to_pred,\n",
                        "    batch_size=64,\n",
                        "    num_workers=16,\n",
                        "    #train_oversampling=2,\n",
                        "    validation_split=0.05,\n",
                        "    do_gene_pos='../data/main/biomart_pos.parquet',\n",
                        "    test_split=0.05)\n",
                        "testfiles = datamodule.setup()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-03-14 09:16:21,556:ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                                    "wandb: Currently logged in as: jkobject (ml4ig). Use `wandb login --relogin` to force relogin\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "wandb version 0.16.4 is available!  To upgrade, please run:\n",
                                          " $ pip install wandb --upgrade"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Tracking run with wandb version 0.16.2"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Run data is saved locally in <code>../data/tensorboard/wandb/run-20240314_091623-heig0ijx</code>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/heig0ijx' target=\"_blank\">buttermilk-flambee-65</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/heig0ijx' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/heig0ijx</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "ename": "NameError",
                              "evalue": "name 'model' is not defined",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WandbLogger\n\u001b[1;32m      4\u001b[0m wandb_logger \u001b[38;5;241m=\u001b[39m WandbLogger(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscprint_test\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/tensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m wandb_logger\u001b[38;5;241m.\u001b[39mwatch(\u001b[43mmodel\u001b[49m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, log_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, log_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#tlogger.log_graph(model)\u001b[39;00m\n",
                                    "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
                              ]
                        }
                  ],
                  "source": [
                        "from lightning.pytorch.loggers import TensorBoardLogger\n",
                        "from lightning.pytorch.loggers import WandbLogger\n",
                        "\n",
                        "wandb_logger = WandbLogger(project=\"scprint_test\", save_dir=\"../data/tensorboard\")\n",
                        "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
                        "\n",
                        "#tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
                        "#tlogger.log_graph(model)\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "#from lightning.pytorch.profilers import PyTorchProfiler\n",
                        "#pytorch_prof = PyTorchProfiler(\"../data/tensorboard\", emit_nvtx=False, group_by_input_shape=True, record_shapes=True, profile_memory=True, with_stack=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../data/tensorboard/\"),)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using bfloat16 Automatic Mixed Precision (AMP)\n",
                                    "GPU available: False, used: False\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n"
                              ]
                        }
                  ],
                  "source": [
                        "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
                        "trainingmode = TrainingMode(\n",
                        "    do_denoise=True, \n",
                        "    noise=[0.3],\n",
                        "    do_cce=True, \n",
                        "    #cce_sim=0.6, \n",
                        "    do_ecs=True, \n",
                        "    #ecs_threshold = 0.4, \n",
                        "    #ecs_scale = 0.05,\n",
                        "    #class_scale = 0.08,\n",
                        "    do_mvc=False, \n",
                        "    do_adv_cls=False,\n",
                        "    do_next_tp=False, \n",
                        "    mask_ratio=[], \n",
                        "    warmup_duration= 500, \n",
                        "    weight_decay= 0.01, \n",
                        "    fused_adam= True,)\n",
                        "es = EarlyStopping(patience=2, monitor='val_loss')\n",
                        "swa = StochasticWeightAveraging(swa_lrs= 0.01)\n",
                        "lrm = LearningRateMonitor(logging_interval=\"epoch\")\n",
                        "#lrf = LearningRateFinder(mode=\"exponential\",)\n",
                        "# TODO: to check that the class hierarchy are really ordered from 1-2-3-4... as well (oredered dict)\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=100, max_time={\"hours\": 2}, limit_train_batches=50, limit_val_batches=10, callbacks=[chckp, es, lrm,  swa, trainingmode], accumulate_grad_batches=1, reload_dataloaders_every_n_epochs=1)#, logger=tlogger) #detect_anomaly=True, fast_dev_run=20, overfit_batches=10, limit_train_batches=1, limit_val_batches=0\n",
                        "#logger=wandb_logger,"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using bfloat16 Automatic Mixed Precision (AMP)\n",
                                    "You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n",
                                    "GPU available: False, used: False\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n"
                              ]
                        }
                  ],
                  "source": [
                        "# sanity. should be overfiting.\n",
                        "trainer = Trainer(precision=\"16-mixed\", max_epochs=1000, limit_val_batches=0, check_val_every_n_epoch=1000, log_every_n_steps=1000, detect_anomaly=True, overfit_batches=30, gradient_clip_val=100,\n",
                        "reload_dataloaders_every_n_epochs=1000) #logger=wandb_logger) limit_train_batches=1"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-04-11 12:16:05,415:INFO - Created a temporary directory at /local/scratch/tmp/tmpyvw1ii0p\n",
                                    "2024-04-11 12:16:05,416:INFO - Writing /local/scratch/tmp/tmpyvw1ii0p/_remote_module_non_scriptable.py\n",
                                    "2024-04-11 12:16:05,416:INFO - Writing /local/scratch/tmp/tmpyvw1ii0p/_remote_module_non_scriptable.py\n"
                              ]
                        }
                  ],
                  "source": [
                        "model = scPrint(\n",
                        "    genes = datamodule.genes,\n",
                        "    d_model = d_model,\n",
                        "    nhead = 4,\n",
                        "    nlayers = 4,\n",
                        "    layers_cls = [d_model],\n",
                        "    labels = datamodule.labels,\n",
                        "    cls_hierarchy = datamodule.cls_hierarchy,\n",
                        "    dropout= 0.1,\n",
                        "    transformer = \"flash\",\n",
                        "    precpt_gene_emb = gene_emb,\n",
                        "    gene_pos_enc = datamodule.gene_pos,\n",
                        "    mvc_decoder = \"inner product\",\n",
                        "    label_decoders = datamodule.decoders,\n",
                        "    fused_dropout_add_ln = False,\n",
                        "    num_batch_labels = datamodule.num_datasets,\n",
                        "    checkpointing=True,\n",
                        "    prenorm=True,\n",
                        "    num_heads_kv=None,\n",
                        ")\n",
                        "\n",
                        "#model.do_denoise = True\n",
                        "#model.noise = [.5]\n",
                        "#model.do_cce = True\n",
                        "#model.do_mvc = False\n",
                        "#model.do_adv_cls = False\n",
                        "#model.do_generate = True\n",
                        "#model.weight_decay = 1e-4\n",
                        "#model.fused_adam = True\n",
                        "#model.lr_patience = 1\n",
                        "#model.optim = \"adamW\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 42,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "these files will be considered test datasets:\n",
                                    "    /home/ml4ig1/scprint/.lamindb/BljRloq1xjcxRNDpejzI.h5ad\n",
                                    "    /home/ml4ig1/scprint/.lamindb/yBCKp6HmXuHa0cZptMo7.h5ad\n",
                                    "perc test:  0.0057480725242011555\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                                    "\n",
                                    "   | Name                            | Type                         | Params\n",
                                    "----------------------------------------------------------------------------------\n",
                                    "0  | gene_encoder                    | GeneEncoder                  | 5.7 M \n",
                                    "1  | expr_encoder                    | ContinuousValueEncoder       | 17.0 K\n",
                                    "2  | pos_encoder                     | PositionalEncoding           | 0     \n",
                                    "3  | label_encoder                   | CategoryValueEncoder         | 1.0 K \n",
                                    "4  | depth_encoder                   | ContinuousValueEncoder       | 17.0 K\n",
                                    "5  | norm_and_dropout                | Sequential                   | 256   \n",
                                    "6  | transformer                     | FlashTransformerEncoder      | 793 K \n",
                                    "7  | expr_decoder                    | ExprDecoder                  | 33.7 K\n",
                                    "8  | cls_decoders                    | ModuleDict                   | 130 K \n",
                                    "9  | grad_reverse_discriminator_loss | AdversarialDiscriminatorLoss | 45.0 K\n",
                                    "10 | mvc_decoder                     | MVCDecoder                   | 65.7 K\n",
                                    "----------------------------------------------------------------------------------\n",
                                    "1.1 M     Trainable params\n",
                                    "5.7 M     Non-trainable params\n",
                                    "6.8 M     Total params\n",
                                    "27.328    Total estimated model params size (MB)\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "7f45a335b2f14f2baa034679f80306c9",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Sanity Checking: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(640)_full_training()\n",
                                    "    638 \n",
                                    "    639         pdb.set_trace()\n",
                                    "--> 640         batch_idx = batch.get(\"dataset\", None)\n",
                                    "    641         timepoint = None\n",
                                    "    642 \n",
                                    "\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
                                    "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(640)_full_training()\n",
                                    "    638 \n",
                                    "    639         pdb.set_trace()\n",
                                    "--> 640         batch_idx = batch.get(\"dataset\", /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(640)_full_training()\n",
                                    "    638 \n",
                                    "    639         pdb.set_trace()\n",
                                    "--> 640         batch_idx = batch.get(\"dataset\", None)\n",
                                    "    641         timepoint = None\n",
                                    "    642 \n",
                                    "\n",
                                    "tensor([81, 46,  7, 45, 22, 80, 58, 46, 73, 66, 79, 66,  2, 28, 73,  2, 48, 28,\n",
                                    "        34, 44, 19, 65, 65, 26, 49, 63, 65, 65, 26, 53, 65, 84, 73,  7, 87, 68,\n",
                                    "        41,  2, 46, 50, 73, 45,  8, 79, 57, 74,  2,  8,  6, 65,  2, 19, 54, 19,\n",
                                    "        15, 19,  8,  3, 73, 77, 65, 81, 46, 87], device='cuda:0')\n",
                                    "tensor([[133,   3,   3,  -1,  -1,   1],\n",
                                    "        [130,   3,   7,  -1,   0,   1],\n",
                                    "        [277,   3,   2,   5,   1,   1],\n",
                                    "        [267,   3,   2,   5,   0,   1],\n",
                                    "        [267,   3,   2,   5,   0,   1],\n",
                                    "        [267,   3,   2,   5,   0,   1],\n",
                                    "        [209,   5,   2,  -1,   1,   1],\n",
                                    "        [ 17,   3,  10,  -1,   0,   1],\n",
                                    "        [190,   3,   2,  -1,   1,   0],\n",
                                    "        [209,   3,  10,  -1,   1,   0],\n",
                                    "        [ 33,   3,   2,   5,   1,   1],\n",
                                    "        [209,   3,  10,  -1,   1,   0],\n",
                                    "        [247,   3,  10,  -1,   0,   1],\n",
                                    "        [277,   2,   5,  -1,   0,   1],\n",
                                    "        [182,   3,   2,  -1,   0,   0],\n",
                                    "        [227,   3,  10,  -1,   1,   1],\n",
                                    "        [282,  10,   2,   5,   0,   1],\n",
                                    "        [274,   2,   5,  -1,   0,   1],\n",
                                    "        [  0,  12,   9,  -1,   1,   1],\n",
                                    "        [224,   3,   5,  -1,   0,   1],\n",
                                    "        [226,   3,   2,  -1,   1,   1],\n",
                                    "        [252,   3,   1,   0,   0,   1],\n",
                                    "        [252,   3,   1,   0,   0,   1],\n",
                                    "        [226,   4,   2,   4,   0,   1],\n",
                                    "        [267,   3,   2,   5,   0,   1],\n",
                                    "        [209,   3,   9,   3,   1,   1],\n",
                                    "        [195,   3,   1,   0,   1,   1],\n",
                                    "        [106,   3,   1,   0,   1,   1],\n",
                                    "        [226,   4,   2,   4,   0,   1],\n",
                                    "        [241,   3,   5,  -1,   0,   1],\n",
                                    "        [246,   3,   1,   0,   1,   1],\n",
                                    "        [285,   3,  10,  -1,   0,   1],\n",
                                    "        [190,   3,   2,  -1,   1,   0],\n",
                                    "        [  9,  19,   2,   5,   1,   1],\n",
                                    "        [267,   3,   2,   5,   0,   1],\n",
                                    "        [162,   3,   5,  -1,   1,   1],\n",
                                    "        [ 94,   3,  10,  -1,   1,   1],\n",
                                    "        [227,   7,  10,  -1,   0,   1],\n",
                                    "        [147,   3,   2,  -1,   0,   1],\n",
                                    "        [150,   3,   6,  -1,   1,   1],\n",
                                    "        [190,   3,   2,  -1,   1,   0],\n",
                                    "        [267,   3,   2,   5,   0,   1],\n",
                                    "        [161,   7,  10,  -1,   0,   1],\n",
                                    "        [ 41,   3,   2,   5,   0,   1],\n",
                                    "        [288,   3,   5,  -1,   1,   1],\n",
                                    "        [ 99,   6,   8,  -1,   0,   0],\n",
                                    "        [130,   7,  10,   5,   0,   1],\n",
                                    "        [130,   7,  10,   5,   0,   1],\n",
                                    "        [137,   3,   5,  -1,   0,   1],\n",
                                    "        [252,   3,   1,   0,   0,   1],\n",
                                    "        [101,   7,  10,   5,   1,   1],\n",
                                    "        [156,   3,   2,   5,   0,   1],\n",
                                    "        [146,   3,   5,  -1,  -1,   0],\n",
                                    "        [ 19,   4,   2,   5,   0,   1],\n",
                                    "        [288,   3,   5,  -1,   0,   1],\n",
                                    "        [ 19,  19,   2,   5,   0,   1],\n",
                                    "        [209,   3,  10,   5,   0,   1],\n",
                                    "        [ 99,   0,   8,  -1,   0,   0],\n",
                                    "        [182,   3,   2,  -1,   1,   0],\n",
                                    "        [ 99,   3,   8,   5,   1,   1],\n",
                                    "        [213,   3,   1,   0,   1,   1],\n",
                                    "        [190,   3,   3,  -1,  -1,   1],\n",
                                    "        [101,   3,  10,  -1,   1,   1],\n",
                                    "        [267,   3,   2,   5,   0,   1]], device='cuda:0', dtype=torch.int32)\n",
                                    "torch.Size([64, 1200])\n",
                                    "tensor([[  815,  4809, 16414,  ...,  3644, 14925,  8815],\n",
                                    "        [ 5296,  1274, 13912,  ...,  8719, 18520, 13200],\n",
                                    "        [ 5835, 13679,   229,  ..., 11320,  8096,  7816],\n",
                                    "        ...,\n",
                                    "        [  612,   473,  9067,  ...,  2050, 10932,  5343],\n",
                                    "        [16904,  1821, 17105,  ..., 12049,   651,  6879],\n",
                                    "        [18002,  9314, 12002,  ..., 14939,  9353, 11687]], device='cuda:0',\n",
                                    "       dtype=torch.int32)\n",
                                    "tensor([25284, 26355, 32989,  ..., 33668, 27918, 27463], device='cuda:0',\n",
                                    "       dtype=torch.int32)\n"
                              ]
                        }
                  ],
                  "source": [
                        "trainer.fit(model, datamodule=datamodule)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "%reload_ext tensorboard\n",
                        "%tensorboard --logdir=\"../data/tensorboard\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "#wandb_logger.finalize(status=\"aborted\")\n",
                        "torch.cuda.empty_cache()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "----\n",
                        "# TODO: connect with maestro people to ask for longer compute time \n",
                        "# TODO: do the same to jean zay (0.5 day)\n",
                        "# TODO: run a large training on maestro (0.5 day)\n",
                        "# TODO: make a model benchmark package (continue from where I left off) (4 days)\n",
                        "# TODO: debug the gene embedding creation\n",
                        "# TODO: create embedding & make it work for the 4-5 species in the dataset (1 days) "
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "scprint",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.10.0"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
