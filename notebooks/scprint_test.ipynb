{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/bin/lamin\", line 5, in <module>\n",
      "    from lamin_cli.__main__ import main\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/lamin_cli/__main__.py\", line 11, in <module>\n",
      "    import rich_click as click\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/__init__.py\", line 73, in <module>\n",
      "    from . import rich_click as rich_click\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/rich_click.py\", line 6, in <module>\n",
      "    import rich.columns\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/columns.py\", line 7, in <module>\n",
      "    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/console.py\", line 57, in <module>\n",
      "    from .markup import render as render_markup\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 674, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n",
      "  File \"<frozen importlib._bootstrap>\", line 541, in _init_module_attrs\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! lamin load scprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/bitsandbytes/cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "ðŸ’¡ connected lamindb: jkobject/scprint\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "from scprint import scPrint\n",
    "from scprint.trainer import TrainingMode\n",
    "from scdataloader import DataModule \n",
    "import pandas as pd\n",
    "from scdataloader.utils import load_genes\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: drop tissue & dev stage until part or is taken in account\n",
    "\n",
    "hierarchical_labels = [\n",
    "    \"cell_type_ontology_term_id\", #1\n",
    "    # \"tissue_ontology_term_id\",\n",
    "    \"disease_ontology_term_id\", # 2\n",
    "#    \"development_stage_ontology_term_id\",\n",
    "    \"assay_ontology_term_id\", #3\n",
    "    'self_reported_ethnicity_ontology_term_id', #4\n",
    "]\n",
    "labels_to_pred = hierarchical_labels+[\n",
    "    'sex_ontology_term_id', #5\n",
    "    \"organism_ontology_term_id\", #6\n",
    "]\n",
    "all_labels = labels_to_pred+[\n",
    "    #'dataset_id',\n",
    "    'cell_culture',\n",
    "    \"heat_diff\",\n",
    "    \"total_counts\",\n",
    "    \"nnz\",\n",
    "    \"dpt_group\",\n",
    "]\n",
    "\n",
    "gene_emb = '../data/main/gene_embeddings.parquet'\n",
    "d_model=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "won't do any check but we recommend to have your dataset coming from local storage\n",
      "100.0% are aligned\n",
      "total dataset size is 97.032938749 Gb\n",
      "---\n",
      "dataset contains:\n",
      "     4926521 cells\n",
      "     127057 genes\n",
      "     11 labels\n",
      "     6 clss_to_pred\n",
      "     4 hierarchical_clss\n",
      "     2 organisms\n",
      "dataset contains 229 classes to predict\n",
      "\n",
      "seeing a string: loading gene positions as biomart parquet file\n",
      "these files will be considered test datasets:\n",
      "    /pasteur/zeus/projets/p02/ml4ig_hot/Users/jkalfon/scprint/.lamindb/BljRloq1xjcxRNDpejzI.h5ad\n",
      "    /pasteur/zeus/projets/p02/ml4ig_hot/Users/jkalfon/scprint/.lamindb/yBCKp6HmXuHa0cZptMo7.h5ad\n",
      "perc test:  0.0057480725242011555\n"
     ]
    }
   ],
   "source": [
    "datamodule = DataModule(\n",
    "    collection_name=\"preprocessed dataset\",\n",
    "    gene_embeddings=gene_emb,\n",
    "    all_labels=all_labels,\n",
    "    hierarchical_labels=hierarchical_labels,\n",
    "    organisms=[\"NCBITaxon:9606\", \"NCBITaxon:10090\"],\n",
    "    how=\"random expr\",\n",
    "    max_len=1200,\n",
    "    add_zero_genes=0,\n",
    "    # how much more you will see the most present vs less present category \n",
    "    weight_scaler=10,\n",
    "    label_to_weight=labels_to_pred,\n",
    "    label_to_pred=labels_to_pred,\n",
    "    batch_size=64,\n",
    "    num_workers=16,\n",
    "    #train_oversampling=2,\n",
    "    validation_split=0.05,\n",
    "    do_gene_pos='../data/main/biomart_pos.parquet',\n",
    "    test_split=0.05)\n",
    "testfiles = datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to transform an scGPT checkpoint to an scPrint's\n",
    "# ckpt = torch.load(\"../../scGPT/save/model_e6.pt\")\n",
    "# scPrint.load_from_checkpoint(\"../../scGPT/save/model_e6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 09:16:21,556:ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: jkobject (ml4ig). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../data/tensorboard/wandb/run-20240314_091623-heig0ijx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/heig0ijx' target=\"_blank\">buttermilk-flambee-65</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/heig0ijx' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/heig0ijx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WandbLogger\n\u001b[1;32m      4\u001b[0m wandb_logger \u001b[38;5;241m=\u001b[39m WandbLogger(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscprint_test\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/tensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m wandb_logger\u001b[38;5;241m.\u001b[39mwatch(\u001b[43mmodel\u001b[49m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, log_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, log_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#tlogger.log_graph(model)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"scprint_test\", save_dir=\"../data/tensorboard\")\n",
    "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
    "\n",
    "#tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
    "#tlogger.log_graph(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lightning.pytorch.profilers import PyTorchProfiler\n",
    "#pytorch_prof = PyTorchProfiler(\"../data/tensorboard\", emit_nvtx=False, group_by_input_shape=True, record_shapes=True, profile_memory=True, with_stack=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../data/tensorboard/\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /pasteur/appa/homes/jkalfon/miniconda3/envs/scprint1 ...\n",
      "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:552: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
    "trainingmode = TrainingMode(\n",
    "    do_denoise=True, \n",
    "    noise=[0.4],\n",
    "    do_cce=True, \n",
    "    do_ecs=True, \n",
    "    do_mvc=False, \n",
    "    do_next_tp=False, \n",
    "    mask_ratio=[], \n",
    "    warmup_duration= 500, \n",
    "    weight_decay= 0.01, \n",
    "    fused_adam= True)\n",
    "es = EarlyStopping(patience=2, monitor='val_loss')\n",
    "swa = StochasticWeightAveraging(swa_lrs= 0.01)\n",
    "lrm = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "#lrf = LearningRateFinder(mode=\"exponential\",)\n",
    "# TODO: to check that the class hierarchy are really ordered from 1-2-3-4... as well (oredered dict)\n",
    "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=100, max_time={\"hours\": 2}, limit_train_batches=50, limit_val_batches=10, callbacks=[chckp, es, lrm,  swa, trainingmode], accumulate_grad_batches=1, reload_dataloaders_every_n_epochs=1)#, logger=tlogger) #detect_anomaly=True, fast_dev_run=20, overfit_batches=10, limit_train_batches=1, limit_val_batches=0\n",
    "#logger=wandb_logger,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cell_type_ontology_term_id',\n",
       " 'disease_ontology_term_id',\n",
       " 'assay_ontology_term_id',\n",
       " 'self_reported_ethnicity_ontology_term_id',\n",
       " 'sex_ontology_term_id',\n",
       " 'organism_ontology_term_id']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# sanity. should be overfiting.\n",
    "trainer = Trainer(precision=\"16-mixed\", max_epochs=1000, limit_val_batches=0, check_val_every_n_epoch=1000, log_every_n_steps=1000, detect_anomaly=True, overfit_batches=30, gradient_clip_val=100,\n",
    "reload_dataloaders_every_n_epochs=1000) #logger=wandb_logger) limit_train_batches=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 10:56:45,156:INFO - Created a temporary directory at /local/scratch/tmp/tmpeswgujof\n",
      "2024-04-12 10:56:45,157:INFO - Writing /local/scratch/tmp/tmpeswgujof/_remote_module_non_scriptable.py\n",
      "2024-04-12 10:56:45,157:INFO - Writing /local/scratch/tmp/tmpeswgujof/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "model = scPrint(\n",
    "    genes = datamodule.genes,\n",
    "    d_model = d_model,\n",
    "    nhead = 4,\n",
    "    nlayers = 4,\n",
    "    layers_cls = [d_model],\n",
    "    labels = datamodule.labels,\n",
    "    cls_hierarchy = datamodule.cls_hierarchy,\n",
    "    dropout= 0.1,\n",
    "    transformer = \"flash\",\n",
    "    precpt_gene_emb = gene_emb,\n",
    "    gene_pos_enc = datamodule.gene_pos,\n",
    "    mvc_decoder = \"inner product\",\n",
    "    label_decoders = datamodule.decoders,\n",
    "    fused_dropout_add_ln = False,\n",
    "    num_batch_labels = datamodule.num_datasets,\n",
    "    checkpointing=True,\n",
    "    prenorm=True,\n",
    "    num_heads_kv=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these files will be considered test datasets:\n",
      "    /home/ml4ig1/scprint/.lamindb/BljRloq1xjcxRNDpejzI.h5ad\n",
      "    /home/ml4ig1/scprint/.lamindb/yBCKp6HmXuHa0cZptMo7.h5ad\n",
      "perc test:  0.0057480725242011555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                            | Type                         | Params\n",
      "----------------------------------------------------------------------------------\n",
      "0  | gene_encoder                    | GeneEncoder                  | 5.7 M \n",
      "1  | expr_encoder                    | ContinuousValueEncoder       | 17.0 K\n",
      "2  | pos_encoder                     | PositionalEncoding           | 0     \n",
      "3  | label_encoder                   | CategoryValueEncoder         | 1.0 K \n",
      "4  | depth_encoder                   | ContinuousValueEncoder       | 17.0 K\n",
      "5  | norm_and_dropout                | Sequential                   | 256   \n",
      "6  | transformer                     | FlashTransformerEncoder      | 793 K \n",
      "7  | expr_decoder                    | ExprDecoder                  | 33.7 K\n",
      "8  | cls_decoders                    | ModuleDict                   | 130 K \n",
      "9  | grad_reverse_discriminator_loss | AdversarialDiscriminatorLoss | 45.0 K\n",
      "10 | mvc_decoder                     | MVCDecoder                   | 65.7 K\n",
      "----------------------------------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "5.7 M     Non-trainable params\n",
      "6.8 M     Total params\n",
      "27.328    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f45a335b2f14f2baa034679f80306c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(640)_full_training()\n",
      "    638 \n",
      "    639         pdb.set_trace()\n",
      "--> 640         batch_idx = batch.get(\"dataset\", None)\n",
      "    641         timepoint = None\n",
      "    642 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(640)_full_training()\n",
      "    638 \n",
      "    639         pdb.set_trace()\n",
      "--> 640         batch_idx = batch.get(\"dataset\", /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(640)_full_training()\n",
      "    638 \n",
      "    639         pdb.set_trace()\n",
      "--> 640         batch_idx = batch.get(\"dataset\", None)\n",
      "    641         timepoint = None\n",
      "    642 \n",
      "\n",
      "tensor([81, 46,  7, 45, 22, 80, 58, 46, 73, 66, 79, 66,  2, 28, 73,  2, 48, 28,\n",
      "        34, 44, 19, 65, 65, 26, 49, 63, 65, 65, 26, 53, 65, 84, 73,  7, 87, 68,\n",
      "        41,  2, 46, 50, 73, 45,  8, 79, 57, 74,  2,  8,  6, 65,  2, 19, 54, 19,\n",
      "        15, 19,  8,  3, 73, 77, 65, 81, 46, 87], device='cuda:0')\n",
      "tensor([[133,   3,   3,  -1,  -1,   1],\n",
      "        [130,   3,   7,  -1,   0,   1],\n",
      "        [277,   3,   2,   5,   1,   1],\n",
      "        [267,   3,   2,   5,   0,   1],\n",
      "        [267,   3,   2,   5,   0,   1],\n",
      "        [267,   3,   2,   5,   0,   1],\n",
      "        [209,   5,   2,  -1,   1,   1],\n",
      "        [ 17,   3,  10,  -1,   0,   1],\n",
      "        [190,   3,   2,  -1,   1,   0],\n",
      "        [209,   3,  10,  -1,   1,   0],\n",
      "        [ 33,   3,   2,   5,   1,   1],\n",
      "        [209,   3,  10,  -1,   1,   0],\n",
      "        [247,   3,  10,  -1,   0,   1],\n",
      "        [277,   2,   5,  -1,   0,   1],\n",
      "        [182,   3,   2,  -1,   0,   0],\n",
      "        [227,   3,  10,  -1,   1,   1],\n",
      "        [282,  10,   2,   5,   0,   1],\n",
      "        [274,   2,   5,  -1,   0,   1],\n",
      "        [  0,  12,   9,  -1,   1,   1],\n",
      "        [224,   3,   5,  -1,   0,   1],\n",
      "        [226,   3,   2,  -1,   1,   1],\n",
      "        [252,   3,   1,   0,   0,   1],\n",
      "        [252,   3,   1,   0,   0,   1],\n",
      "        [226,   4,   2,   4,   0,   1],\n",
      "        [267,   3,   2,   5,   0,   1],\n",
      "        [209,   3,   9,   3,   1,   1],\n",
      "        [195,   3,   1,   0,   1,   1],\n",
      "        [106,   3,   1,   0,   1,   1],\n",
      "        [226,   4,   2,   4,   0,   1],\n",
      "        [241,   3,   5,  -1,   0,   1],\n",
      "        [246,   3,   1,   0,   1,   1],\n",
      "        [285,   3,  10,  -1,   0,   1],\n",
      "        [190,   3,   2,  -1,   1,   0],\n",
      "        [  9,  19,   2,   5,   1,   1],\n",
      "        [267,   3,   2,   5,   0,   1],\n",
      "        [162,   3,   5,  -1,   1,   1],\n",
      "        [ 94,   3,  10,  -1,   1,   1],\n",
      "        [227,   7,  10,  -1,   0,   1],\n",
      "        [147,   3,   2,  -1,   0,   1],\n",
      "        [150,   3,   6,  -1,   1,   1],\n",
      "        [190,   3,   2,  -1,   1,   0],\n",
      "        [267,   3,   2,   5,   0,   1],\n",
      "        [161,   7,  10,  -1,   0,   1],\n",
      "        [ 41,   3,   2,   5,   0,   1],\n",
      "        [288,   3,   5,  -1,   1,   1],\n",
      "        [ 99,   6,   8,  -1,   0,   0],\n",
      "        [130,   7,  10,   5,   0,   1],\n",
      "        [130,   7,  10,   5,   0,   1],\n",
      "        [137,   3,   5,  -1,   0,   1],\n",
      "        [252,   3,   1,   0,   0,   1],\n",
      "        [101,   7,  10,   5,   1,   1],\n",
      "        [156,   3,   2,   5,   0,   1],\n",
      "        [146,   3,   5,  -1,  -1,   0],\n",
      "        [ 19,   4,   2,   5,   0,   1],\n",
      "        [288,   3,   5,  -1,   0,   1],\n",
      "        [ 19,  19,   2,   5,   0,   1],\n",
      "        [209,   3,  10,   5,   0,   1],\n",
      "        [ 99,   0,   8,  -1,   0,   0],\n",
      "        [182,   3,   2,  -1,   1,   0],\n",
      "        [ 99,   3,   8,   5,   1,   1],\n",
      "        [213,   3,   1,   0,   1,   1],\n",
      "        [190,   3,   3,  -1,  -1,   1],\n",
      "        [101,   3,  10,  -1,   1,   1],\n",
      "        [267,   3,   2,   5,   0,   1]], device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([64, 1200])\n",
      "tensor([[  815,  4809, 16414,  ...,  3644, 14925,  8815],\n",
      "        [ 5296,  1274, 13912,  ...,  8719, 18520, 13200],\n",
      "        [ 5835, 13679,   229,  ..., 11320,  8096,  7816],\n",
      "        ...,\n",
      "        [  612,   473,  9067,  ...,  2050, 10932,  5343],\n",
      "        [16904,  1821, 17105,  ..., 12049,   651,  6879],\n",
      "        [18002,  9314, 12002,  ..., 14939,  9353, 11687]], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([25284, 26355, 32989,  ..., 33668, 27918, 27463], device='cuda:0',\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=\"../data/tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_logger.finalize(status=\"aborted\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----\n",
    "# TODO: connect with maestro people to ask for longer compute time \n",
    "# TODO: do the same to jean zay (0.5 day)\n",
    "# TODO: run a large training on maestro (0.5 day)\n",
    "# TODO: make a model benchmark package (continue from where I left off) (4 days)\n",
    "# TODO: debug the gene embedding creation\n",
    "# TODO: create embedding & make it work for the 4-5 species in the dataset (1 days) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
